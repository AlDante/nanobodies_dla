{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.2 64-bit",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "53d305e6caef14f179c1acd9c8c2a99fedb8d9bfe18ef39be302c8d4f156abed"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2020_09_27_08_46\n"
    }
   ],
   "source": [
    "import datetime\n",
    "TIMESTAMP = format(f\"{datetime.datetime.now():%Y_%m_%d_%H_%M}\")\n",
    "print(TIMESTAMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = '2019_12_19_16_41'\n",
    "ENV='high'\n",
    "dataset='gst'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('./data/{}/{}'.format(dataset, TIMESTAMP)):\n",
    "    os.makedirs('./data/{}/{}'.format(dataset, TIMESTAMP), mode=0o777)\n",
    "if not os.path.exists('./data/{}/{}/logs'.format(dataset, TIMESTAMP)):\n",
    "    os.makedirs('./data/{}/{}/logs'.format(dataset, TIMESTAMP), mode=0o777)\n",
    "if not os.path.exists('./data/{}/{}/best_models'.format(dataset, TIMESTAMP)):\n",
    "    os.makedirs('./data/{}/{}/best_models'.format(dataset, TIMESTAMP), mode=0o777)\n",
    "if not os.path.exists('./data/{}/{}/graph'.format(dataset, TIMESTAMP)):\n",
    "    os.makedirs('./data/{}/{}/graph'.format(dataset, TIMESTAMP), mode=0o777)\n",
    "if not os.path.exists('./data/{}/{}/filters'.format(dataset, TIMESTAMP)):\n",
    "    os.makedirs('./data/{}/{}/filters'.format(dataset, TIMESTAMP), mode=0o777)\n",
    "if not os.path.exists('./data/{}/{}/cluster_analysis'.format(dataset, TIMESTAMP)):\n",
    "    os.makedirs('./data/{}/{}/cluster_analysis'.format(dataset, TIMESTAMP), mode=0o777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_tf\n",
    "import utils\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seqs = utils.load_pickle('./data/{}/{}_{}.pickle'.format(dataset,dataset,ENV))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_size = 0\n",
    "for _id, seq_data in all_seqs.items():\n",
    "    max_seq_size = max(max_seq_size,seq_data['sequence'][0].__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_dataset = []\n",
    "_train_labels = []\n",
    "_train_ids = []\n",
    "\n",
    "_test_dataset = []\n",
    "_test_labels = []\n",
    "_test_ids = []\n",
    "hsa_train_id, hsa_test_id = utils.cluster_res_to_dataset('./data/{}/{}_{}.results.clstr'.format(dataset,dataset,ENV))\n",
    "LOW_AFFINITY=0\n",
    "HIGH_AFFINITY=2\n",
    "for _id, seq_data in all_seqs.items():\n",
    "    lab = int(seq_data['labels'][0])\n",
    "    if _id in hsa_train_id:\n",
    "        # in general\n",
    "        # _train_labels.append(lab)\n",
    "        # _train_dataset.append(utils_tf.to_one_hot_prot(seq_data['sequence'][0], max_seq_size))\n",
    "        # _train_ids.append(_id)\n",
    "        \n",
    "        # compare high vs low\n",
    "        if LOW_AFFINITY == lab:\n",
    "            _train_labels.append(lab)\n",
    "            _train_dataset.append(utils_tf.to_one_hot_prot(seq_data['sequence'][0], max_seq_size))\n",
    "            _train_ids.append(_id)\n",
    "        elif HIGH_AFFINITY == lab:\n",
    "            _train_labels.append(1)\n",
    "            _train_dataset.append(utils_tf.to_one_hot_prot(seq_data['sequence'][0], max_seq_size))\n",
    "            _train_ids.append(_id)\n",
    "    else:\n",
    "        # _test_labels.append(lab)\n",
    "        # _test_dataset.append(utils_tf.to_one_hot_prot(seq_data['sequence'][0], max_seq_size))\n",
    "        # _test_ids.append(_id)\n",
    "\n",
    "        # compare high vs low\n",
    "        if LOW_AFFINITY == lab:\n",
    "            _test_labels.append(lab)\n",
    "            _test_dataset.append(utils_tf.to_one_hot_prot(seq_data['sequence'][0], max_seq_size))\n",
    "            _test_ids.append(_id)\n",
    "        elif HIGH_AFFINITY == lab:\n",
    "            _test_labels.append(1)\n",
    "            _test_dataset.append(utils_tf.to_one_hot_prot(seq_data['sequence'][0], max_seq_size))\n",
    "            _test_ids.append(_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.to_npz('./data/{}/{}/train_{}.npz'.format(dataset, TIMESTAMP, ENV), _train_dataset, _train_labels)\n",
    "utils.to_npz('./data/{}/{}/test_{}.npz'.format(dataset, TIMESTAMP,ENV), _test_dataset, _test_labels)\n",
    "\n",
    "utils.to_pickle(_train_ids, './data/{}/{}/train_ids_{}.pickle'.format(dataset, TIMESTAMP,ENV))\n",
    "utils.to_pickle(_test_ids, './data/{}/{}/test_ids_{}.pickle'.format(dataset, TIMESTAMP, ENV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model then analyse. Run the following command: train.py ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN = 'K5Z523NP'\n",
    "filter_length=7\n",
    "input_folder = './data/{}/{}'.format(dataset,TIMESTAMP)\n",
    "model = './data/{}/{}/best_models/{}/DeepNano_{}_{}.h5'.format(dataset, TIMESTAMP, RUN,ENV, RUN)\n",
    "test = './data/{}/{}/test_{}.npz'.format(dataset,TIMESTAMP, ENV)\n",
    "all_data_ids_fn = './data/{}/all_data_ids_{}.pickle'.format(dataset, ENV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fee004161f0> and will run it as-is.\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\nCause: Bad argument number for Name: 4, expecting 3\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\nWARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fee004161f0> and will run it as-is.\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\nCause: Bad argument number for Name: 4, expecting 3\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
    }
   ],
   "source": [
    "test_data, test_labels, classifier, layer_outputs, activations = utils_tf.predict(model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\nfindfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
    }
   ],
   "source": [
    "import model_analysis\n",
    "import numpy as np\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "import utils_jer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters, biases = classifier.layers[0].get_weights()\n",
    "f_min, f_max = filters.min(), filters.max()\n",
    "filters = (filters) / (f_max - f_min)\n",
    "filters_mask = np.round(filters, decimals=1)\n",
    "filters[filters_mask == 0] = 0\n",
    "for filt in range(filters.shape[2]):\n",
    "    filter_to_show_jer = np.zeros((filter_length,21))\n",
    "    filter_to_show_jer[:,0:20] = filters[:,:,filt]\n",
    "    fig = utils_jer.sequence_logo(filter_to_show_jer,figsize=(filter_length,filter_length), title=\"Filter num: {}\".format(filt), show=False, data_type='weights');\n",
    "    fig.savefig(path.join(input_folder, './filters/{}_{}_{}_filt{}.svg'.format(dataset, ENV, RUN, filt)));\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fed31a634c0> and will run it as-is.\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\nCause: Bad argument number for Name: 4, expecting 3\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\nWARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fed31a634c0> and will run it as-is.\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\nCause: Bad argument number for Name: 4, expecting 3\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
    }
   ],
   "source": [
    "model_analysis.model_analysis(\n",
    "        test,\n",
    "        input_folder,\n",
    "        model,\n",
    "        all_data_ids_fn,\n",
    "        ENV,\n",
    "        './data/{}/{}/test_ids_{}.pickle'.format(dataset,TIMESTAMP,ENV),\n",
    "        '{}_{}'.format(dataset,RUN),\n",
    "        [0,1],\n",
    "        97\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}